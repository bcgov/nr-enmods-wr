apiVersion: batch/v1
kind: CronJob
metadata:
  name: aqi-weekly-sync
  namespace: d23a53-dev
spec:
  schedule: "0 0 * * 6" #change this to every saturday at midnight
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 2
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: db-sync
              image: postgres:15
              env:
                # Database credentials from openshift secrets
                - name: POSTGRES_HOST
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: POSTGRES_HOST
                - name: POSTGRES_USER
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: POSTGRES_USER
                - name: POSTGRES_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: POSTGRES_PASSWORD
                - name: POSTGRES_DBNAME
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: POSTGRES_DATABASE

                # S3 Credentials from openshift secrets
                - name: S3_BUCKET
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: S3_BUCKET
                - name: S3_BUCKET_PATH
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: S3_BUCKET_PATH
                - name: S3_REGION
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: S3_REGION
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: AWS_ACCESS_KEY_ID
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: "{{ .Release.Name }}-database"
                      key: AWS_SECRET_ACCESS_KEY
              args:
                - /bin/sh
                - "-c"
                - |
                  echo "Starting AQI weekly sync job..."

                  echo "Getting latest directory (prefix) from S3..."
                  LATEST_DIR=$(aws s3api list-objects-v2 --bucket "$S3_BUCKET" --prefix "$S3_BUCKET_PATH/" --delimiter '/' --query "CommonPrefixes[].Prefix" --output text | tr ' ' '\n' | sort | tail -n 1)

                  if [ -z "$LATEST_DIR" ]; then
                    echo "ERROR: No directories found under prefix $S3_BUCKET_PATH"
                    exit 1
                  fi

                  echo "Latest directory (prefix) is: $LATEST_DIR"
                  echo "Listing .csv.gz files inside the directory..."

                  FILES=$(aws s3api list-objects-v2 --bucket "$S3_BUCKET" --prefix "$LATEST_DIR" --query "Contents[?ends_with(Key, '.csv.gz')].Key" --output text)

                  if [ -z "$FILES" ]; then
                    echo "ERROR: No .csv.gz files found in $LATEST_DIR"
                    exit 1
                  fi

                  echo "Found Files:"
                  echo "$FILES"
                  echo

                  # Convert to SQL Array format
                  S3_KEY_ARRAY=$(printf "%s" "$FILES" | tr ' ' '\n' | awk '{printf "'\''%s'\'',", $0}' | sed 's/,$//')
                  S3_KEY_ARRAY="ARRAY[$S3_KEY_ARRAY]"

                  echo "Final SQL array: $S3_KEY_ARRAY"
                  echo

                  export DATABASE_URL="postgresql://$POSTGRES_USER:$POSTGRES_PASSWORD@$POSTGRES_HOST/$POSTGRES_DBNAME"

                  echo "Running load from S3..."
                  psql "$DATABASE_URL" \
                    -c "SELECT run_aqi_s3_load('$S3_BUCKET', $S3_KEY_ARRAY, '$S3_REGION', NULL, '$AWS_ACCESS_KEY_ID', '$AWS_SECRET_ACCESS_KEY', '$AWS_SESSION_TOKEN');"

                  echo "Load from S3 completed."
                  echo "Running table swap..."
                  psql "$DATABASE_URL" \
                    -c "SELECT run_aqi_table_swap('AQI_AWS_S3_SYNC');"
                  echo "Table swap completed."
                  echo "AQI hourly sync completed."
          restartPolicy: OnFailure
